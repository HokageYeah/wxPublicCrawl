import httpx
import urllib.parse
import time
import math
import random
from typing import Dict, Any
from fastapi import HTTPException, Request
import logging
from loguru import logger
from app.schemas.wx_data import ArticleDetailRequest, ArticleListRequest, CookieTokenRequest, PreloginRequest, WebreportRequest, StartLoginRequest
import json
from app.utils.wx_article_handle import save_html_to_local, parse_wx_common_data, upload_to_aliyun
from bs4 import BeautifulSoup
from app.utils.src_path import get_temp_file_path
from app.decorators.request_decorator import extract_wx_credentials
# from PIL import Image
cookies = {
    # "appmsglist_action_3964406050": "card",
    # "RK": "ja198JWedK",
    # "ptcz": "7ebea765d075dffa6ef04c81508c0ef29c004910a7de50ef4633e50b9dd7434f",
    # "uin": "o2410292164",
    # "rewardsn": "",
    # "ua_id": "19NhLcjPInWpmsVLAAAAAIM_YaNha4ekik8fWssHpDM=",
    # "_clck": "10obs8|1|fw1|0",
    # "wxuin": "47635853929480",
    "mm_lang": "zh_CN",
    # "uuid": "6f292948090057fcd00f7d9674b27b46",
    # "rand_info": "CAESIHiKJrBtZF3Nj0pH/eWbld4llPH7qXV2f30yVSzzeen8",
    # "slave_bizuin": "3964406050",
    # "data_bizuin": "3964406050",
    # "bizuin": "3964406050",
    # "data_ticket": "b1gFFOVFXWJSOPFv0x0kdWNGqnLvTLJDdroZ3mTQuqaINx+2qd30rDuheprNxukk",
    "slave_sid": "WDlkVDhLOFllMDh4SEt4ZjMwUVlRcTg3VnQzd01ERTVjZWw4Q1pvSklsejMyZGlxYVNzME5aUFk4UHM0UWJFZG9URG5GeUdOMllqMGxGSmJBY3BMOUZuS1Z4Tjdzb3Y4UjEyYW45ZTNDOWljamZQMnFlZloxdWNFbFkwUzNCNWhWUGRjRm5qcDFvWGVKRU9y",
    "slave_user": "gh_82bb5e0f80e3",
    # "xid": "2bf279896be76b2a04adde420df9a89f",
    # "_clsk": "9ll88u|1747636404886|6|1|mp.weixin.qq.com/weheat-agent/payload/record"
}
token = "159333899"

# é”™è¯¯å¤„ç†
def handle_error(base_resp):
    ret = base_resp.get('ret',0)
    err_msg = base_resp.get('err_msg','')
    if ret != 0:
        raise HTTPException(status_code=400, detail=f"HTTPé”™è¯¯: {err_msg}")
    return base_resp

@extract_wx_credentials(cookies, token)
async def fetch_wx_public(request: Request, query: str, begin: int, count: int):
    """è·å–å¾®ä¿¡å…¬ä¼—å·"""
    # ä» request.state ä¸­è·å–è£…é¥°å™¨å¤„ç†åçš„ cookies å’Œ token
    merged_cookies = request.state.wx_cookies
    final_token = request.state.wx_token
    
    print('ğŸ” [DEBUG] æŸ¥è¯¢å‚æ•° query:', query)
    
    url = f"https://mp.weixin.qq.com/cgi-bin/searchbiz?action=search_biz&begin={begin}&count={count}&query={query}&token={final_token}&lang=zh_CN&f=json&ajax=1"

    try:
        async with httpx.AsyncClient(verify=False) as client:
            logging.info(f"æ­£åœ¨è¯·æ±‚URL: {url}")
            logger.info(f"æ­£åœ¨è¯·æ±‚cookies: {merged_cookies}ï¼Œtoken: {final_token}")
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            }
            # ä½¿ç”¨åˆå¹¶åçš„ cookies
            response = await client.get(url, headers=headers, timeout=10, cookies=merged_cookies)
            response.raise_for_status()
            # æ•´ç†æˆjson
            json_data = json.loads(response.text)
            base_resp = json_data.get('base_resp', {})
            handle_error(base_resp)
            return json_data.get('list', [])
    except httpx.HTTPStatusError as e:
        raise HTTPException(status_code=e.response.status_code, detail=f"HTTPé”™è¯¯: {e}")
    except httpx.RequestError as e:
        raise HTTPException(status_code=500, detail=f"è¯·æ±‚é”™è¯¯: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æœªçŸ¥é”™è¯¯: {e}")

@extract_wx_credentials(cookies, token)
async def fetch_wx_article_list(request: Request, params: ArticleListRequest):
    """ä½¿ç”¨Queryå‚æ•°è·å–å¾®ä¿¡å…¬ä¼—å·æ–‡ç« è¯¦æƒ…"""
    # ä» request.state ä¸­è·å–è£…é¥°å™¨å¤„ç†åçš„ cookies å’Œ token
    merged_cookies = request.state.wx_cookies
    final_token = request.state.wx_token
    if len(params.query) <= 0:
        url = f"https://mp.weixin.qq.com/cgi-bin/appmsgpublish?sub=list&begin={params.begin}&count={params.count}&fakeid={params.wx_public_id}&type=101_1&free_publish_type=1&sub_action=list_ex&token={final_token}&lang=zh_CN&f=json&ajax=1"
    else:
        url = f"https://mp.weixin.qq.com/cgi-bin/appmsgpublish?sub=search&search_field=7&begin={params.begin}&count={params.count}&query={params.query}&fakeid={params.wx_public_id}&type=101_1&free_publish_type=1&sub_action=list_ex&token={final_token}&lang=zh_CN&f=json&ajax=1"
    print('url', url)
    try:
        async with httpx.AsyncClient(verify=False) as client:
            response = await client.get(url,timeout=10,cookies=merged_cookies)
            response.raise_for_status()
            json_data = json.loads(response.text)
            base_resp = json_data.get('base_resp',{})
            handle_error(base_resp)
            publish_page = json_data.get('publish_page',"")
            publish_page_obj = json.loads(publish_page,)
            publish_page_obj['publish_list'] = [json.loads(item["publish_info"]) for item in publish_page_obj['publish_list']]
            return publish_page_obj
    except httpx.HTTPStatusError as e:
        raise HTTPException(status_code=e.response.status_code, detail=f"HTTPé”™è¯¯: {e}")


@extract_wx_credentials(cookies, token)
async def fetch_wx_article_detail_by_link(request: Request, request_data: ArticleDetailRequest):
    """æ ¹æ®æ–‡ç« é“¾æ¥è¯·æ±‚å¾—åˆ°æ–‡ç« è¯¦æƒ…ï¼ˆéœ€è¦ä¼ é€’å…¬ä¼—å·idä»¥åŠå…¬ä¼—å·åç§°ï¼Œåšç½‘ç«™æœ¬åœ°åŒ–ä¿å­˜ä½¿ç”¨ï¼‰"""
    # ä» request.state ä¸­è·å–è£…é¥°å™¨å¤„ç†åçš„ cookies å’Œ token
    merged_cookies = request.state.wx_cookies
    final_token = request.state.wx_token
    article_link = request_data.article_link
    wx_public_id = request_data.wx_public_id
    wx_public_name = request_data.wx_public_name
    is_upload_to_aliyun = request_data.is_upload_to_aliyun # æ˜¯å¦ä¸Šä¼ åˆ°é˜¿é‡Œäº‘
    is_save_to_local = request_data.is_save_to_local # æ˜¯å¦ä¿å­˜åˆ°æœ¬åœ°
    save_to_local_path = request_data.save_to_local_path # ä¿å­˜åˆ°æœ¬åœ°è·¯å¾„
    save_to_local_file_name = request_data.save_to_local_file_name # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶å
    
    try:
        # ä¸»åŠ¨æŠ›å‡ºå¼‚å¸¸ï¼Œè®¾ç½®è¿”å›ç›¸åº”ä½“
        # raise HTTPException(status_code=400, detail="æµ‹è¯•å¼‚å¸¸")
        # æŠ›å‡ºä¸€ä¸ªä¸šåŠ¡å¼‚å¸¸
        async with httpx.AsyncClient(verify=False) as client:
            logging.info(f"æ­£åœ¨è¯·æ±‚æ–‡ç« è¯¦æƒ…URL: {article_link}")
            
            headers = {
                "Referer": article_link,
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            }
            response = await client.get(article_link, headers=headers, cookies=merged_cookies)
            response.raise_for_status()
            # è¿”å›ä¸€ä¸ªhtml
            html_content = response.text
            oss_file_path = ""
            local_file_path = ""
            if is_save_to_local:
                # å­˜å‚¨htmlåˆ°æœ¬åœ°
                kwargs = {
                    "wx_public_name": wx_public_name,
                    "wx_public_id": wx_public_id,
                    "path_name": 'wx_public' if save_to_local_path == '' else '',
                    "save_to_local_path": save_to_local_path,
                    "save_to_local_file_name": save_to_local_file_name
                }
                local_file_path = save_html_to_local(html_content, **kwargs)
            if local_file_path != "" and is_upload_to_aliyun:
                oss_file_path = upload_to_aliyun(local_file_path)
            return {
                "local_file_path": local_file_path,
                "oss_file_path": oss_file_path
            }
    except httpx.HTTPStatusError as e:
        raise HTTPException(status_code=e.response.status_code, detail=f"HTTPé”™è¯¯: {e}")
    except httpx.RequestError as e:
        raise HTTPException(status_code=500, detail=f"è¯·æ±‚é”™è¯¯: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æœªçŸ¥é”™è¯¯: {e}")
    
async def fetch_set_wx_cookie_token(params: CookieTokenRequest):
    """è®¾ç½®cookieã€token"""
    # è®¾ç½®å…¨å±€å˜é‡
    global cookies, token
    # åˆ¤æ–­cookiesçš„ç±»å‹
    if isinstance(params.cookie, str):
        # å°†cookieè½¬æ¢ä¸ºå­—å…¸
        cookies = json.loads(params.cookie)
    else:
        cookies = params.cookie.__dict__
    token = params.token
    print('cookies---token', cookies, token)
    return {"message": "cookieã€tokenè®¾ç½®æˆåŠŸ"}


# ------------------------------------------------------------
# å¾®ä¿¡å…¬ä¼—å·ç™»å½•æµç¨‹
# ------------------------------------------------------------


# å…¬å…±è¯·æ±‚å¤´
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Content-Type": "application/x-www-form-urlencoded",
    "Referer": "https://mp.weixin.qq.com/",
}
cookies = {}
newsessionid = ""
token = ""


def restore_cookies_and_token(session_cookies: Dict[str, Any], session_token: str = ""):
    """ä»ä¼šè¯æ•°æ®ä¸­æ¢å¤å…¨å±€cookieså’Œtoken
    
    Args:
        session_cookies: ä¼šè¯ä¸­ä¿å­˜çš„cookies
        session_token: ä¼šè¯ä¸­ä¿å­˜çš„token (å¯é€‰)
    """
    global cookies, token
    if session_cookies:
        cookies = session_cookies
        print(f"âœ“ å·²æ¢å¤ cookies: {len(cookies)} ä¸ª")
    if session_token:
        token = session_token
        print(f"âœ“ å·²æ¢å¤ token")


# å¾®ä¿¡å…¬ä¼—å·ç™»å½•æµç¨‹ - ç¬¬ä¸€æ­¥ï¼šé¢„ç™»å½•è·å–å¿½ç•¥å¯†ç åˆ—è¡¨
async def fetch_prelogin(request_data: PreloginRequest):
    """å¾®ä¿¡å…¬ä¼—å·ç™»å½•æµç¨‹ - ç¬¬ä¸€æ­¥ï¼šé¢„ç™»å½•è·å–å¿½ç•¥å¯†ç åˆ—è¡¨
    
    POST /cgi-bin/bizlogin
    Host: https://mp.weixin.qq.com
    action=prelogin
    """
    url = "https://mp.weixin.qq.com/cgi-bin/bizlogin"
    
    data = {
        "action": request_data.action
    }
    
    
    try:
        async with httpx.AsyncClient(verify=False) as client:
            logging.info(f"æ­£åœ¨è¯·æ±‚é¢„ç™»å½•URL: {url}")
            response = await client.post(url, data=data, headers=headers, timeout=10)
            print('ç¬¬ä¸€æ­¥ï¼šé¢„ç™»å½•è·å–å¿½ç•¥å¯†ç åˆ—è¡¨---response', response.text)
            print('ç¬¬ä¸€æ­¥ï¼šé¢„ç™»å½•è·å–å¿½ç•¥å¯†ç åˆ—è¡¨---cookie', response.cookies)
            response.raise_for_status()
            
            # è§£æå“åº”
            json_data = json.loads(response.text)
            base_resp = json_data.get('base_resp', {})
            handle_error(base_resp)
            
            # è¿”å›é¢„ç™»å½•ç»“æœ
            return json_data
    except httpx.HTTPStatusError as e:
        raise HTTPException(status_code=e.response.status_code, detail=f"HTTPé”™è¯¯: {e}")
    except httpx.RequestError as e:
        raise HTTPException(status_code=500, detail=f"è¯·æ±‚é”™è¯¯: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æœªçŸ¥é”™è¯¯: {e}")
    
# å¾®ä¿¡å…¬ä¼—å·ç™»å½•æµç¨‹ - ç¬¬äºŒæ­¥ï¼šå¼€å§‹ç™»å½•
async def fetch_startlogin(request_data: StartLoginRequest):
    """å¾®ä¿¡å…¬ä¼—å·ç™»å½•æµç¨‹ - ç¬¬äºŒæ­¥ï¼šå¼€å§‹ç™»å½•
    
    POST /cgi-bin/bizlogin?action=startlogin
    Host: https://mp.weixin.qq.com
    
    userlang=zh_CN
    redirect_url=
    login_type=3
    sessionid=sessionid
    """
    url = "https://mp.weixin.qq.com/cgi-bin/bizlogin?action=startlogin"
    global newsessionid
    newsessionid = await generate_session_id()
    data = {
        "userlang": request_data.userlang,
        "redirect_url": request_data.redirect_url,
        "login_type": request_data.login_type,
        "sessionid": request_data.sessionid or newsessionid
    }
    
    try:
        async with httpx.AsyncClient(verify=False) as client:
            logging.info(f"æ­£åœ¨è¯·æ±‚è·å–äºŒç»´ç URL: {url}")
            response = await client.post(url, data=data, headers=headers, timeout=10)
            print('ç¬¬äºŒæ­¥ï¼šè·å–äºŒç»´ç ---response', response.text)
            print('ç¬¬äºŒæ­¥ï¼šè·å–äºŒç»´ç ---cookie---data', response.cookies, data)
            global cookies
            cookies = {cookie[0]: cookie[1] for cookie in response.cookies.items()}
            # æ„å»ºcookieå­—ç¬¦ä¸²
            cookie_str = '; '.join([f"{k}={v}" for k, v in cookies.items()])
            print('ç¬¬äºŒæ­¥ï¼šè·å–äºŒç»´ç ---cookie_str', cookie_str)
            print('ç¬¬äºŒæ­¥ï¼šè·å–äºŒç»´ç ---cookies', cookies)
            response.raise_for_status()
            
            # è§£æå“åº”
            json_data = json.loads(response.text)
            base_resp = json_data.get('base_resp', {})
            handle_error(base_resp)
            
            # è¿”å›äºŒç»´ç ä¿¡æ¯
            return {
                **json_data,
                'cookie_str': cookie_str,
                'cookies': cookies
            }
    except httpx.HTTPStatusError as e:
        raise HTTPException(status_code=e.response.status_code, detail=f"HTTPé”™è¯¯: {e}")
    except httpx.RequestError as e:
        raise HTTPException(status_code=500, detail=f"è¯·æ±‚é”™è¯¯: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æœªçŸ¥é”™è¯¯: {e}")

# å¾®ä¿¡å…¬ä¼—å·ç™»å½•æµç¨‹ - ç¬¬ä¸‰æ­¥ï¼šä¸ŠæŠ¥ä¿¡æ¯
async def fetch_webreport(request_data: WebreportRequest):
    """å¾®ä¿¡å…¬ä¼—å·ç™»å½•æµç¨‹ - ç¬¬ä¸‰æ­¥ï¼šä¸ŠæŠ¥ä¿¡æ¯
    
    POST /cgi-bin/webreport
    Host: https://mp.weixin.qq.com
    reportJson={"devicetype":1,"newsessionid":"172059629456827","optype":1,"page_state":3,"log_id":19015}
    """
    url = "https://mp.weixin.qq.com/cgi-bin/webreport"
    
    # æ„å»ºreportJson
    report_json = {
        "devicetype": request_data.devicetype,
        "newsessionid": request_data.sessionid or newsessionid,
        "optype": request_data.optype,
        "page_state": request_data.page_state,
        "log_id": request_data.log_id
    }
    print('report_json', report_json)
    
    data = {
        "reportJson": json.dumps(report_json)
    }
    
    try:
        async with httpx.AsyncClient(verify=False) as client:
            logging.info(f"æ­£åœ¨è¯·æ±‚ä¸ŠæŠ¥URL: {url}")
            response = await client.post(url, data=data, headers=headers, timeout=10)
            # print('response--------', response.json())
            print('ç¬¬ä¸‰æ­¥ï¼šä¸ŠæŠ¥ä¿¡æ¯---response', response.text)
            print('ç¬¬ä¸‰æ­¥ï¼šä¸ŠæŠ¥ä¿¡æ¯---cookie', response.cookies)
            print('ç¬¬ä¸‰æ­¥ï¼šä¸ŠæŠ¥ä¿¡æ¯---data', data)
            response.raise_for_status()
            
            # è¿”å›ä¸ŠæŠ¥ç»“æœ
            return {**response.json(), "newsessionid": report_json["newsessionid"]}
    except httpx.HTTPStatusError as e:
        raise HTTPException(status_code=e.response.status_code, detail=f"HTTPé”™è¯¯: {e}")
    except httpx.RequestError as e:
        raise HTTPException(status_code=500, detail=f"è¯·æ±‚é”™è¯¯: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æœªçŸ¥é”™è¯¯: {e}")

# å¾®ä¿¡å…¬ä¼—å·ç™»å½•æµç¨‹ - ç¬¬å››æ­¥ï¼šè·å–å¾®ä¿¡ç™»å½•äºŒç»´ç 
async def fetch_get_wx_login_qrcode(request: Request):
    """è·å–å¾®ä¿¡ç™»å½•äºŒç»´ç 
    
    è¿”å›äºŒç»´ç å›¾åƒçš„äºŒè¿›åˆ¶æ•°æ®
    """
    random_num = int(time.time() * 1000)    # å½“å‰æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
    url = f"https://mp.weixin.qq.com/cgi-bin/scanloginqrcode?action=getqrcode&random={random_num}"
    
    # è·å–è¯·æ±‚å¤´ä¸­çš„cookie
    cookies_str = request.headers.get('Cookie', '')
    if not cookies_str:
        # å¦‚æœæ²¡æœ‰cookieï¼Œä½¿ç”¨é»˜è®¤cookie
        cookies = {}
        logger.warning("No cookies found in request headers, using default empty cookies")
    else:
        # è§£æcookie
        try:
            cookies = {cookie.split('=')[0].strip(): cookie.split('=')[1].strip() 
                    for cookie in cookies_str.split(';') if '=' in cookie}
        except Exception as e:
            logger.error(f"Error parsing cookies: {e}")
            cookies = {}
    
    logger.info(f"ç¬¬å››æ­¥ï¼šè·å–å¾®ä¿¡ç™»å½•äºŒç»´ç ---cookies: {cookies}")
    
    try:
        async with httpx.AsyncClient(verify=False) as client:
            response = await client.get(url, timeout=10, cookies=cookies)
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.status_code != 200:
                logger.error(f"è·å–äºŒç»´ç å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                raise HTTPException(status_code=response.status_code, 
                                  detail=f"è·å–äºŒç»´ç å¤±è´¥: {response.text}")
            
            # è®°å½•äºŒç»´ç å¤§å°
            logger.info(f"äºŒç»´ç å¤§å°: {len(response.content)} bytes")
            
            # ä¿å­˜äºŒç»´ç åˆ°æœ¬åœ°æ–‡ä»¶ç”¨äºè°ƒè¯•
            # è·å–ä¸´æ—¶æ–‡ä»¶è·¯å¾„
            # åœ¨ .app åŒ…æ¨¡å¼ä¸‹ï¼š
            # å½“å‰å·¥ä½œç›®å½• (CWD) è¢«è®¾ç½®ä¸º .app åŒ…å†…éƒ¨
            # è¿™ä¸ªç›®å½•æ˜¯åªè¯»çš„ï¼ˆmacOS å®‰å…¨æœºåˆ¶ï¼‰
            # æ‰€ä»¥æ— æ³•å†™å…¥æ–‡ä»¶
            qrcode_file_path = get_temp_file_path('qrcode.png')
            with open(qrcode_file_path, 'wb') as f:
                f.write(response.content)
            print('äºŒç»´ç ä¿å­˜è·¯å¾„:', qrcode_file_path)
                
            # ç›´æ¥è¿”å›äºŒè¿›åˆ¶å†…å®¹
            return response.content
    except Exception as e:
        logger.error(f"è·å–äºŒç»´ç æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–äºŒç»´ç å¤±è´¥: {str(e)}")


# å¾®ä¿¡å…¬ä¼—å·ç™»å½•æµç¨‹ - ç¬¬äº”æ­¥ï¼šè·å–äºŒç»´ç çŠ¶æ€
async def fetch_get_qrcode_status(request: Request):
    """è·å–äºŒç»´ç çŠ¶æ€"""
    url = "https://mp.weixin.qq.com/cgi-bin/scanloginqrcode?action=ask&fingerprint=9b1ea719e1ba482a27d45364d3c7f877&token=&lang=zh_CN&f=json"
    async with httpx.AsyncClient(verify=False) as client:
        cookies =  request.headers.get('Cookie')
        # è½¬æ¢æˆå¯¹è±¡
        cookies = {cookie.split('=')[0]: cookie.split('=')[1] for cookie in cookies.split(';')}
        response = await client.get(url, timeout=10, cookies=cookies)
        print('ç¬¬äº”æ­¥ï¼šè·å–äºŒç»´ç çŠ¶æ€---cookies-----', cookies)
        print('ç¬¬äº”æ­¥ï¼šè·å–äºŒç»´ç çŠ¶æ€---response', response.text)
        response.raise_for_status()
        json_data = json.loads(response.text)
        base_resp = json_data.get('base_resp', {})
        handle_error(base_resp)
        return json_data

# å¾®ä¿¡å…¬ä¼—å·ç™»å½•æµç¨‹ - ç¬¬å…­æ­¥ï¼šè·å–ç™»å½•ä¿¡æ¯
async def fetch_get_login_info(request: Request):
    """è·å–ç™»å½•ä¿¡æ¯"""
    url = "https://mp.weixin.qq.com/cgi-bin/bizlogin?action=login"
    global newsessionid
    data = {
        "userlang": "zh_CN",
        "redirect_url": "",
        "cookie_forbidden": 0,
        "cookie_cleaned": 0,
        "plugin_used": 0,
        "login_type": 3,
        "fingerprint": "",
        "token": "",
    }
    async with httpx.AsyncClient(verify=False) as client:
        request_cookies =  request.headers.get('Cookie')
        # è½¬æ¢æˆå¯¹è±¡
        request_cookies = {cookie.split('=')[0]: cookie.split('=')[1] for cookie in request_cookies.split(';')}
        response = await client.post(url, data=data, timeout=10, headers=headers, cookies=request_cookies)
        print('ç¬¬å…­æ­¥ï¼šè·å–ç™»å½•ä¿¡æ¯---response', response.text)
        print('ç¬¬å…­æ­¥ï¼šè·å–ç™»å½•ä¿¡æ¯---cookie', request_cookies)
        print('ç¬¬å…­æ­¥ï¼šè·å–ç™»å½•ä¿¡æ¯---data', data)
        response.raise_for_status()

        response_cookies = {cookie[0]: cookie[1] for cookie in response.cookies.items()}
        # æ„å»ºcookieå­—ç¬¦ä¸²
        cookie_str = '; '.join([f"{k}={v}" for k, v in response_cookies.items()])
        print('ç¬¬å…­æ­¥ï¼šè·å–ç™»å½•ä¿¡æ¯---response-cookie_str', cookie_str)
        print('ç¬¬å…­æ­¥ï¼šè·å–ç™»å½•ä¿¡æ¯---response-cookies', response_cookies)
        response.raise_for_status()
        
        # è§£æå“åº”
        json_data = json.loads(response.text)
        base_resp = json_data.get('base_resp', {})
        handle_error(base_resp)
        redirect_url = json_data.get('redirect_url', '')
        # /cgi-bin/home?t=home/index&lang=zh_CN&token=21304194"
        # è·å–token
        global token, cookies
        token = redirect_url.split('token=')[1]
        cookies = response_cookies
        print('ç¬¬å…­æ­¥ï¼šè·å–ç™»å½•ä¿¡æ¯---global token', token)
        print('ç¬¬å…­æ­¥ï¼šè·å–ç™»å½•ä¿¡æ¯---global cookies', cookies)
        return {
            **json_data,
            'cookie_str': cookie_str,
            'token': token
        }
# å¾®ä¿¡å…¬ä¼—å·ç™»å½•æµç¨‹ - ç¬¬ä¸ƒæ­¥ï¼šéªŒè¯ç”¨æˆ·ä¿¡æ¯
async def fetch_verify_user_info(request: Request, rq_token: str):
    """éªŒè¯ç”¨æˆ·ä¿¡æ¯"""
    global token
    if not rq_token:
        rq_token = token
    print('ç¬¬ä¸ƒæ­¥ï¼šéªŒè¯ç”¨æˆ·ä¿¡æ¯---rq_token', rq_token)
    url = f"https://mp.weixin.qq.com/cgi-bin/home?action=get_finder_live_info&fingerprint=77d0c4a6149482d13b8a9b1dea06ad99&token={rq_token}&lang=zh_CN&f=json&ajax=1"
    async with httpx.AsyncClient(verify=False) as client:
        request_cookies =  request.headers.get('Cookie')
        # è½¬æ¢æˆå¯¹è±¡
        request_cookies = {cookie.split('=')[0]: cookie.split('=')[1] for cookie in request_cookies.split(';')}
        response = await client.get(url, timeout=10, cookies=request_cookies)
        print('ç¬¬ä¸ƒæ­¥ï¼šéªŒè¯ç”¨æˆ·ä¿¡æ¯---response', response.text)
        print('ç¬¬ä¸ƒæ­¥ï¼šéªŒè¯ç”¨æˆ·ä¿¡æ¯---cookie', request_cookies)
        response.raise_for_status()
        return response.text
    
# å¾®ä¿¡å…¬ä¼—å·ç™»å½•æµç¨‹ - ç¬¬å…«æ­¥ï¼šæ ¹æ®é‡å®šå‘è·å–å¾®ä¿¡å…¬ä¼—å·ä¸ªäººç™»å½•ä¿¡æ¯
async def fetch_redirect_login_info(request: Request, redirect_url: str):
    """æ ¹æ®é‡å®šå‘è·å–å¾®ä¿¡å…¬ä¼—å·ä¸ªäººç™»å½•ä¿¡æ¯"""
        # è¯·æ±‚é‡å®šå‘åœ°å€æ ¹æ®é‡å®šå‘åœ°å€è·å–å¾®ä¿¡å…¬ä¼—å·ä¸ªäººç™»å½•ä¿¡æ¯
    url = f"https://mp.weixin.qq.com{redirect_url}"
    async with httpx.AsyncClient(verify=False) as client:
        request_cookies =  request.headers.get('Cookie')
        # è½¬æ¢æˆå¯¹è±¡
        request_cookies = {cookie.split('=')[0]: cookie.split('=')[1] for cookie in request_cookies.split(';')}
        response = await client.get(url, timeout=10, cookies=request_cookies, headers=headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')
        # è§£æHTMLè·å–wx.commonData
        wx_data = parse_wx_common_data(response.text)
        # è§£æå‡º
        print('ç¬¬ä¸ƒæ­¥ï¼šæ ¹æ®é‡å®šå‘è·å–å¾®ä¿¡å…¬ä¼—å·ä¸ªäººç™»å½•ä¿¡æ¯---é‡å®šå‘åœ°å€--wx_data', wx_data)
        return {
            "userInfo": wx_data,
            "cookies": request_cookies,
            "token": token
        }
    

async def generate_session_id():
    """ç”Ÿæˆä¼šè¯ID
    
    JavaScripté€»è¾‘: this.sessionid = new Date().getTime() + "" + Math.floor(Math.random() * 100);
    """
    timestamp = int(time.time() * 1000)  # è·å–å½“å‰æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
    random_num = math.floor(random.random() * 100)  # ç”Ÿæˆ0-99çš„éšæœºæ•°
    session_id = f"{timestamp}{random_num}"  # æ‹¼æ¥æˆä¼šè¯ID
    print('session_id----------', session_id)
    return session_id


async def export_articles_to_excel(articles: list, save_path: str, file_name: str):
    """
    å°†æ–‡ç« åˆ—è¡¨å¯¼å‡ºåˆ°Excelæ–‡ä»¶
    
    å‚æ•°:
        articles: æ–‡ç« åˆ—è¡¨ï¼ŒåŒ…å«aid, title, publish_time, update_time, link
        save_path: ä¿å­˜è·¯å¾„
        file_name: æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        
    è¿”å›:
        dict: åŒ…å«ä¿å­˜è·¯å¾„å’Œæ–‡ä»¶åçš„ç»“æœ
    """
    import pandas as pd
    import os
    from pathlib import Path
    
    try:
        logger.info(f"å¼€å§‹å¯¼å‡ºæ–‡ç« åˆ°Excelï¼Œå…± {len(articles)} ç¯‡æ–‡ç« ")
        
        # å°†Pydanticæ¨¡å‹è½¬æ¢ä¸ºå­—å…¸ï¼ˆå¦‚æœä¼ å…¥çš„æ˜¯æ¨¡å‹å¯¹è±¡ï¼‰
        article_dicts = []
        for article in articles:
            # å¦‚æœæ˜¯Pydanticæ¨¡å‹ï¼Œè½¬æ¢ä¸ºå­—å…¸
            if hasattr(article, 'model_dump'):
                article_dict = article.model_dump()
            elif hasattr(article, 'dict'):
                article_dict = article.dict()
            else:
                article_dict = article
            article_dicts.append(article_dict)
        
        # åˆ›å»ºDataFrameï¼ŒæŒ‰ç…§æŒ‡å®šé¡ºåºï¼šaid, title, publish_time, update_time, link
        df_data = []
        for article in article_dicts:
            df_data.append({
                "æ–‡ç« ID": article.get("aid", "") if isinstance(article, dict) else getattr(article, "aid", ""),
                "æ–‡ç« æ ‡é¢˜": article.get("title", "") if isinstance(article, dict) else getattr(article, "title", ""),
                "å‘å¸ƒæ—¶é—´": article.get("publish_time", "") if isinstance(article, dict) else getattr(article, "publish_time", ""),
                "æ›´æ–°æ—¶é—´": article.get("update_time", "") if isinstance(article, dict) else getattr(article, "update_time", ""),
                "æ–‡ç« é“¾æ¥": article.get("link", "") if isinstance(article, dict) else getattr(article, "link", "")
            })
        
        df = pd.DataFrame(df_data)
        
        # ç¡®ä¿ä¿å­˜è·¯å¾„å­˜åœ¨
        save_dir = Path(save_path)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        # æ„å»ºå®Œæ•´æ–‡ä»¶è·¯å¾„
        full_path = save_dir / f"{file_name}.xlsx"
        
        # å¯¼å‡ºåˆ°Excel
        df.to_excel(full_path, index=False, engine='openpyxl')
        
        logger.info(f"æ–‡ç« å¯¼å‡ºæˆåŠŸ: {full_path}")
        
        return {
            "success": True,
            "file_path": str(full_path),
            "article_count": len(articles)
        }
        
    except ImportError as e:
        logger.error(f"ç¼ºå°‘å¿…è¦çš„åº“: {e}")
        raise HTTPException(status_code=500, detail=f"ç¼ºå°‘å¿…è¦çš„åº“ï¼Œè¯·å®‰è£… pandas å’Œ openpyxl: pip install pandas openpyxl")
    except Exception as e:
        logger.error(f"å¯¼å‡ºExcelå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å¯¼å‡ºExcelå¤±è´¥: {str(e)}")