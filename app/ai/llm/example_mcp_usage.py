"""
MCP-LLMè¿æ¥å™¨ä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨MCPLLMConnectå®ç°AIè‡ªåŠ¨è°ƒç”¨å·¥å…·
"""
import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).resolve().parent.parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from loguru import logger
from app.ai.llm.mcp_llm_connect import MCPLLMConnect
from app.ai.mcp.mcp_client.client_manager import MCPClientManager


# é…ç½®æ—¥å¿—
logger.add(
    "mcp_llm_example.log",
    level="DEBUG",
    filter=lambda r: "MCP" in r["extra"].get("tag", "")
)


async def example_basic_query():
    """ç¤ºä¾‹1: åŸºç¡€æŸ¥è¯¢"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹1: åŸºç¡€æŸ¥è¯¢ï¼ˆAIè‡ªåŠ¨è°ƒç”¨å·¥å…·ï¼‰")
    print("="*60)
    
    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®é™…çš„llm_connå¯¹è±¡
    # è¿™åªæ˜¯æ¼”ç¤ºä»£ç ç»“æ„
    print("âš ï¸  æ­¤ç¤ºä¾‹éœ€è¦å®é™…çš„llm_connå¯¹è±¡ï¼Œè¯·æ ¹æ®é¡¹ç›®å®é™…æƒ…å†µè°ƒæ•´")
    
    # # 1. åˆå§‹åŒ–MCPç®¡ç†å™¨
    # mcp_manager = MCPClientManager(llm_conn)
    # await mcp_manager.init_mcp_clients()
    
    # # 2. åˆ›å»ºè¿æ¥å™¨
    # connector = MCPLLMConnect(mcp_manager)
    
    # # 3. å‘é€æŸ¥è¯¢
    # response = await connector.query("æŸ¥è¯¢åŒ—äº¬çš„å¤©æ°”")
    # print(f"\nAIå›å¤: {response}")


async def example_multi_step_task():
    """ç¤ºä¾‹2: å¤šæ­¥éª¤ä»»åŠ¡"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹2: å¤šæ­¥éª¤ä»»åŠ¡ï¼ˆAIç»„åˆå¤šä¸ªå·¥å…·ï¼‰")
    print("="*60)
    
    # connector = MCPLLMConnect(mcp_manager)
    
    # # AIä¼šè‡ªåŠ¨è§„åˆ’æ­¥éª¤å¹¶è°ƒç”¨å¤šä¸ªå·¥å…·
    # response = await connector.query(
    #     "å¸®æˆ‘ç¿»åˆ°å…¬ä¼—å·åˆ—è¡¨çš„ç¬¬5é¡µï¼Œç„¶åå‘Šè¯‰æˆ‘ç¬¬ä¸€ç¯‡æ–‡ç« çš„æ ‡é¢˜"
    # )
    # print(f"\nAIå›å¤: {response}")
    
    print("ç¤ºä¾‹ä»£ç è¯·å‚è€ƒ README_MCP_LLM.md")


async def example_with_context():
    """ç¤ºä¾‹3: å¸¦ä¸Šä¸‹æ–‡çš„å¯¹è¯"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹3: å¸¦ä¸Šä¸‹æ–‡çš„å¯¹è¯")
    print("="*60)
    
    # connector = MCPLLMConnect(mcp_manager)
    
    # # ç¬¬ä¸€è½®å¯¹è¯
    # response1 = await connector.query("æŸ¥è¯¢åŒ—äº¬çš„å¤©æ°”")
    # print(f"\nè½®1 - AI: {response1}")
    
    # # ç¬¬äºŒè½®å¯¹è¯ï¼ˆAIä¼šè®°ä½ä¹‹å‰çš„å†…å®¹ï¼‰
    # response2 = await connector.query("é‚£ä¸Šæµ·å‘¢ï¼Ÿ")
    # print(f"\nè½®2 - AI: {response2}")
    
    # # æŸ¥çœ‹å¯¹è¯å†å²
    # history = connector.get_conversation_history()
    # print(f"\nå¯¹è¯è½®æ•°: {len(history)}")
    
    print("ç¤ºä¾‹ä»£ç è¯·å‚è€ƒ README_MCP_LLM.md")


async def example_statistics():
    """ç¤ºä¾‹4: ç»Ÿè®¡ä¿¡æ¯"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹4: æŸ¥çœ‹å·¥å…·ä½¿ç”¨ç»Ÿè®¡")
    print("="*60)
    
    # connector = MCPLLMConnect(mcp_manager)
    
    # # æ‰§è¡Œä¸€äº›æŸ¥è¯¢
    # await connector.query("æŸ¥è¯¢å¤©æ°”")
    # await connector.query("ç¿»é¡µ")
    # await connector.query("è·å–æ–‡ç« ")
    
    # # æŸ¥çœ‹ç»Ÿè®¡
    # stats = connector.get_stats()
    # print(f"\nå·¥å…·è°ƒç”¨ç»Ÿè®¡:")
    # print(f"  æ€»è°ƒç”¨æ¬¡æ•°: {stats['tool_calls']['total_calls']}")
    # print(f"  æˆåŠŸ: {stats['tool_calls']['successful_calls']}")
    # print(f"  å¤±è´¥: {stats['tool_calls']['failed_calls']}")
    # print(f"\nå·¥å…·ä½¿ç”¨è¯¦æƒ…:")
    # for tool, count in stats['tool_calls']['tools_used'].items():
    #     print(f"  {tool}: {count}æ¬¡")
    
    print("ç¤ºä¾‹ä»£ç è¯·å‚è€ƒ README_MCP_LLM.md")


async def example_custom_config():
    """ç¤ºä¾‹5: è‡ªå®šä¹‰é…ç½®"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹5: è‡ªå®šä¹‰é…ç½®")
    print("="*60)
    
    # from app.ai.llm.ai_client import AIClient
    
    # # åˆ›å»ºè‡ªå®šä¹‰AIå®¢æˆ·ç«¯
    # custom_ai = AIClient(
    #     model="gpt-4",
    #     temperature=0.3,
    #     max_tokens=2000
    # )
    
    # # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®åˆ›å»ºè¿æ¥å™¨
    # connector = MCPLLMConnect(
    #     mcp_manager=mcp_manager,
    #     ai_client=custom_ai,
    #     max_tool_calls=5  # æœ€å¤š5æ¬¡å·¥å…·è°ƒç”¨
    # )
    
    # response = await connector.query("æ‰§è¡Œå¤æ‚ä»»åŠ¡...")
    # print(f"\nAIå›å¤: {response}")
    
    print("ç¤ºä¾‹ä»£ç è¯·å‚è€ƒ README_MCP_LLM.md")


async def example_error_handling():
    """ç¤ºä¾‹6: é”™è¯¯å¤„ç†"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹6: é”™è¯¯å¤„ç†")
    print("="*60)
    
    # connector = MCPLLMConnect(mcp_manager)
    
    # try:
    #     # å¯èƒ½å¯¼è‡´å·¥å…·è°ƒç”¨å¤±è´¥çš„æŸ¥è¯¢
    #     response = await connector.query("ä½¿ç”¨ä¸å­˜åœ¨çš„å·¥å…·")
    #     print(f"\nAIå›å¤: {response}")
    # except Exception as e:
    #     print(f"\næ•è·åˆ°é”™è¯¯: {e}")
    #     
    #     # æŸ¥çœ‹ç»Ÿè®¡äº†è§£å¤±è´¥åŸå› 
    #     stats = connector.get_stats()
    #     print(f"å¤±è´¥çš„å·¥å…·è°ƒç”¨: {stats['tool_calls']['failed_calls']}")
    
    print("ç¤ºä¾‹ä»£ç è¯·å‚è€ƒ README_MCP_LLM.md")


async def example_streaming():
    """ç¤ºä¾‹7: æµå¼å“åº”ï¼ˆä¸æ”¯æŒå·¥å…·ï¼‰"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹7: æµå¼å“åº”")
    print("="*60)
    
    # connector = MCPLLMConnect(mcp_manager)
    
    # # æµå¼è¾“å‡ºï¼ˆä¸æ”¯æŒå·¥å…·è°ƒç”¨ï¼‰
    # print("\nAIæ­£åœ¨å›ç­”: ", end='')
    # async for chunk in connector.stream_query("è®²ä¸ªæ•…äº‹"):
    #     print(chunk, end='', flush=True)
    # print("\n")
    
    print("âš ï¸  æµå¼æ¨¡å¼æš‚ä¸æ”¯æŒå·¥å…·è°ƒç”¨")
    print("ç¤ºä¾‹ä»£ç è¯·å‚è€ƒ README_MCP_LLM.md")


async def example_pagination_automation():
    """ç¤ºä¾‹8: å®é™…åœºæ™¯ - å…¬ä¼—å·è‡ªåŠ¨ç¿»é¡µ"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹8: å®é™…åœºæ™¯ - å…¬ä¼—å·è‡ªåŠ¨ç¿»é¡µ")
    print("="*60)
    
    # connector = MCPLLMConnect(mcp_manager)
    
    # # è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼ŒAIè‡ªåŠ¨å®Œæˆå¤æ‚ä»»åŠ¡
    # response = await connector.query("""
    #     å¸®æˆ‘æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š
    #     1. ä»å½“å‰é¡µå¼€å§‹ï¼Œè¿ç»­ç¿»5é¡µ
    #     2. è®°å½•æ¯ä¸€é¡µæœ‰å¤šå°‘ç¯‡æ–‡ç« 
    #     3. ç»Ÿè®¡æ€»å…±æœ‰å¤šå°‘ç¯‡æ–‡ç« 
    #     4. ç»™æˆ‘ä¸€ä¸ªæ±‡æ€»æŠ¥å‘Š
    # """)
    
    # print(f"\nAIæŠ¥å‘Š:\n{response}")
    
    print("è¿™æ˜¯MCP-LLMè¿æ¥å™¨çš„æ ¸å¿ƒåº”ç”¨åœºæ™¯ï¼")
    print("AIä¼šè‡ªåŠ¨ï¼š")
    print("  1. è§„åˆ’ä»»åŠ¡æ­¥éª¤")
    print("  2. å¾ªç¯è°ƒç”¨ next_page å·¥å…·")
    print("  3. è°ƒç”¨ get_article_count å·¥å…·")
    print("  4. æ±‡æ€»æ•°æ®ç”ŸæˆæŠ¥å‘Š")
    print("\nç¤ºä¾‹ä»£ç è¯·å‚è€ƒ README_MCP_LLM.md")


async def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("\n" + "ğŸš€ "*20)
    print("MCP-LLMè¿æ¥å™¨ä½¿ç”¨ç¤ºä¾‹é›†åˆ")
    print("ğŸš€ "*20)
    
    try:
        await example_basic_query()
        await example_multi_step_task()
        await example_with_context()
        await example_statistics()
        await example_custom_config()
        await example_error_handling()
        await example_streaming()
        await example_pagination_automation()
        
        print("\n" + "="*60)
        print("âœ… æ‰€æœ‰ç¤ºä¾‹æ¼”ç¤ºå®Œæˆï¼")
        print("="*60)
        print("\nğŸ’¡ æç¤º:")
        print("  1. è¿™äº›ç¤ºä¾‹éœ€è¦å®é™…çš„MCPæœåŠ¡å’Œé…ç½®æ‰èƒ½è¿è¡Œ")
        print("  2. è¯·å‚è€ƒ README_MCP_LLM.md äº†è§£è¯¦ç»†ä½¿ç”¨æ–¹æ³•")
        print("  3. ç¡®ä¿å·²é…ç½® AI_API_KEY å’Œ MCP æœåŠ¡")
        print("  4. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ mcp_llm_example.log äº†è§£è¯¦ç»†æ‰§è¡Œè¿‡ç¨‹")
        
    except Exception as e:
        logger.error(f"ç¤ºä¾‹è¿è¡Œå¤±è´¥: {e}")
        print(f"\nâŒ é”™è¯¯: {e}")


if __name__ == "__main__":
    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    asyncio.run(main())

